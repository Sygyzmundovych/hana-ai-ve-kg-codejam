{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your SAP HANA database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../01-check_setup.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load SQLAlchemy magic extension: https://pypi.org/project/ipython-sql/#description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "\n",
    "# Use `%config SqlMagic` for configuration changes, if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect using SQLAlchemy Dialect for SAP HANA: https://pypi.org/project/sqlalchemy-hana/#description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql hana://{os.environ[\"HANADB_USR\"]}:{os.environ[\"HANADB_PWD\"]}@{os.environ[\"HANADB_URL\"]}:{os.environ[\"HANADB_PRT\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT * FROM \"VECTORS\".\"GOOGLE_NEWS\" WHERE WORD IN ('cat', 'CAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closely related words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find 5 closest related words for **cat** and **CAT** using the [`COSINE_SIMILARITY()` SQL Function](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/cosine-similarity-063e1366a7d54735b98b2513ea4a88c9), but displaying the [`L2DISTANCE()`](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/l2distance) as well.\n",
    "\n",
    "Compare running the query with and without vector index: https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/examples-for-select-statements-using-vector-indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT\n",
    "  RN,\n",
    "  WORD,\n",
    "  RELATED_WORD,\n",
    "  SIMILARITY_SCORE,\n",
    "  L2DISTANCE\n",
    "FROM (\n",
    "  SELECT\n",
    "    B.WORD AS WORD,\n",
    "    A.WORD AS RELATED_WORD,\n",
    "    COSINE_SIMILARITY(A.WV, B.WV) AS SIMILARITY_SCORE,\n",
    "    L2DISTANCE(A.WV, B.WV) AS L2DISTANCE,\n",
    "    ROW_NUMBER() OVER (PARTITION BY B.WORD ORDER BY COSINE_SIMILARITY(A.WV, B.WV) DESC) AS RN\n",
    "  FROM\n",
    "    \"VECTORS\".\"GOOGLE_NEWS\" A,\n",
    "    (SELECT WV, WORD FROM \"VECTORS\".\"GOOGLE_NEWS\" WHERE WORD IN ('cat', 'CAT')) B\n",
    "  WHERE\n",
    "    A.WORD <> B.WORD\n",
    ") AS RankedWords\n",
    "WHERE\n",
    "  RN <= 5\n",
    "ORDER BY\n",
    "  WORD DESC,\n",
    "  SIMILARITY_SCORE DESC\n",
    "WITH HINT (NO_VECTOR_INDEX);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT\n",
    "  RN,\n",
    "  WORD,\n",
    "  RELATED_WORD,\n",
    "  SIMILARITY_SCORE,\n",
    "  L2DISTANCE\n",
    "FROM (\n",
    "  SELECT\n",
    "    B.WORD AS WORD,\n",
    "    A.WORD AS RELATED_WORD,\n",
    "    COSINE_SIMILARITY(A.WV, B.WV) AS SIMILARITY_SCORE,\n",
    "    L2DISTANCE(A.WV, B.WV) AS L2DISTANCE,\n",
    "    ROW_NUMBER() OVER (PARTITION BY B.WORD ORDER BY COSINE_SIMILARITY(A.WV, B.WV) DESC) AS RN\n",
    "  FROM\n",
    "    \"VECTORS\".\"GOOGLE_NEWS\" A,\n",
    "    (SELECT WV, WORD FROM \"VECTORS\".\"GOOGLE_NEWS\" WHERE WORD IN ('cat', 'CAT')) B\n",
    "  WHERE\n",
    "    A.WORD <> B.WORD\n",
    ") AS RankedWords\n",
    "WHERE\n",
    "  RN <= 5\n",
    "ORDER BY\n",
    "  WORD DESC,\n",
    "  SIMILARITY_SCORE DESC\n",
    "WITH HINT (VECTOR_INDEX);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that **cat** is related to pets, and **CAT** is distantly related to some other acronyms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogy queries\n",
    "\n",
    "Having words represented at vectors you can run some vector computations on them, like the analogy queries. \n",
    "\n",
    "The famous example, described as well at Wikipedia, is [\"What is the word related to **queen**, if the word related to **king** is the **man**\"](https://en.wikipedia.org/wiki/Word2vec#Preservation_of_semantic_and_syntactic_relationships)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1='king'\n",
    "related_word1='man'\n",
    "word2='queen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the mix of Python variables `word1`, `related_word1`, `word2` in the SQL statement below.\n",
    "\n",
    "The calculation of **3CosMul** presented in the [Linguistic Regularities in Sparse and Explicit Word Representations](https://aclanthology.org/W14-1618/) by Omer Levy, Yoav Goldberg is used in this SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT \"V3\".\"WORD\" AS \"lookup_word\",\n",
    "       \"V4\".\"WORD\" AS \"related_word\",\n",
    "       ((1+ COSINE_SIMILARITY(\"V4\".\"WV\", \"V3\".\"WV\"))/2 * (1+COSINE_SIMILARITY(\"V4\".\"WV\", \"V2\".\"WV\"))/2) / ((1+COSINE_SIMILARITY(\"V4\".\"WV\", \"V1\".\"WV\"))/2 + 0.000001) AS \"3COSMUL_SCORE\"\n",
    "FROM \"VECTORS\".\"GOOGLE_NEWS\" AS \"V4\"\n",
    "INNER JOIN \"VECTORS\".\"GOOGLE_NEWS\" AS \"V1\" ON \"V1\".\"WORD\"=:word1\n",
    "INNER JOIN \"VECTORS\".\"GOOGLE_NEWS\" AS \"V2\" ON \"V2\".\"WORD\"=:related_word1\n",
    "INNER JOIN \"VECTORS\".\"GOOGLE_NEWS\" AS \"V3\" ON \"V3\".\"WORD\"=:word2\n",
    "WHERE \"V4\".\"WORD\"<>\"V2\".\"WORD\"\n",
    "  AND \"V4\".\"WORD\"<>\"V1\".\"WORD\"\n",
    "  AND \"V4\".\"WORD\"<>\"V3\".\"WORD\"\n",
    "ORDER BY 3 DESC\n",
    "LIMIT 1\n",
    "-- WITH HINT (NO_VECTOR_INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiement with values of variables `word1`, `related_word1`, `word2` above to come up with your own example of the analogy query results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give you an initial idea: try `Monday`, `one`, `Tuesday` ðŸ¤“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, that:\n",
    "1. although it was tained on big amount of text, not all relationships, especally for topics having less coverage on Google News, might be capctured,\n",
    "2. if you loaded only 100000 tokens (words and phrases) out of 3000000 from the original model, it should cover most common words, but will not include all words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
