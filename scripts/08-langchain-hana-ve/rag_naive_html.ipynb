{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../01-check_setup.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "\n",
    "os.environ[\"USER_AGENT\"] = f\"{requests.get('https://httpbin.org/user-agent').json()['user-agent']}\"\n",
    "os.environ[\"USER_AGENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader_sapblog import CustomSAPBlogLoader\n",
    "\n",
    "# Define URLs\n",
    "urls = [\n",
    "    \"https://community.sap.com/t5/blogs/blogarticleprintpage/blog-id/technology-blog-sap/article-id/177423\", # \"New Machine Learning and NLP features in SAP HANA Cloud 2024 Q4\"\n",
    "    \"https://community.sap.com/t5/blogs/blogarticleprintpage/blog-id/technology-blog-sap/article-id/177557\", # \"Text Chunking â€“ An Exciting New NLP Function in SAP HANA Cloud\"\n",
    "    \"https://community.sap.com/t5/blogs/blogarticleprintpage/blog-id/erp-blog-sap/article-id/58847\", # \"New Text Analysis in SAP HANA Cloud Predictive Analysis Library (PAL)\"\n",
    "    \"https://community.sap.com/t5/blogs/blogarticleprintpage/blog-id/erp-blog-sap/article-id/58846\", # \"Text Embedding Service in SAP HANA Cloud Predictive Analysis Library (PAL)\"\n",
    "    \"https://community.sap.com/t5/blogs/blogarticleprintpage/blog-id/technology-blog-sap/article-id/177553\", # \"New Information Retrieval Techniques in SAP HANA Cloud using BM25 and ANNS for Advanced Text Mining\"\n",
    "    \"https://community.sap.com/t5/blogs/blogarticleprintpage/blog-id/erp-blog-sap/article-id/58845\", # \"Dimensionality Reduction of Text Embeddings for Hybrid Prediction Data\"\n",
    "    \"https://community.sap.com/t5/blogs/blogarticleprintpage/blog-id/erp-blog-sap/article-id/58419\", # \"Document Clustering using KMeans and Text Embeddings\"\n",
    "    \"https://community.sap.com/t5/blogs/blogarticleprintpage/blog-id/technology-blog-sap/article-id/176747\", # \"Hybrid Prediction with Tabular and Text Inputs using Hybrid Gradient Boosting Trees\"\n",
    "    \"https://community.sap.com/t5/blogs/blogarticleprintpage/blog-id/technology-blog-sap/article-id/177560\", # \"Exploring ML Explainability in SAP HANA PAL - AutoML\"\n",
    "\n",
    "]\n",
    "\n",
    "# Load and process articles\n",
    "loader = CustomSAPBlogLoader(urls)\n",
    "(documents := loader.load()).__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check the length of each article's content\n",
    "for doc in documents:\n",
    "    print(doc.metadata[\"source\"], len(doc.page_content), end=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_to_hana = myconn.connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.hanavector import HanaDB\n",
    "from embedder_saphana import HanaEmbeddings\n",
    "\n",
    "db = HanaDB(\n",
    "    embedding=HanaEmbeddings(connection_to_hana), connection=connection_to_hana, table_name=\"MY_LANGCHAIN_EMBEDDINGS\"\n",
    ")\n",
    "\n",
    "print(f\"Table to be used is {db.table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.delete(filter={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "db.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text splitting, preparing articles's text for vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_langchain_tab = myconn.table(db.table_name).add_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_langchain_tab.get_table_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 128) \n",
    "\n",
    "hdf_langchain_tab.head(1).collect().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the Text Splitter with recursive-splitting, available with hana-ml 2.23\n",
    "from hana_ml.text.text_splitter import TextSplitter\n",
    "\n",
    "splitter = TextSplitter(split_type='recursive', chunk_size=1024, overlap=64)\n",
    "#splitter._extend_pal_parameter({'GLOBAL_SEPARATOR':'[. ]', 'KEEP_SEPARATOR':1})\n",
    "splitted_text = splitter.split_text(\n",
    "    hdf_langchain_tab.select('ID', 'VEC_TEXT'), \n",
    "    order_status=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None) \n",
    "\n",
    "print(splitted_text.shape)\n",
    "display(splitter.statistics_.collect())\n",
    "\n",
    "display(splitted_text.select(\"*\", ('LENGTH(\"CONTENT\")', \"CHUNCK_SIZE\")).head(10).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text Embeddings in SAP HANA Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Number of records selected for further processing: {splitted_text.count()}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating Text Embeddings in SAP HANA Cloud with the new PAL function, function available with hana-ml 2.23.\n",
    "from hana_ml.text.pal_embeddings import PALEmbeddings\n",
    "pe = PALEmbeddings(model_version='SAP_GXY.20250407')\n",
    "textembeddings = pe.fit_transform(splitted_text, key=\"SUB_ID\", target=[\"CONTENT\"], thread_number=10, batch_size=10) #, max_token_num=512\n",
    "print(f\"{textembeddings.count()} records processed in {round(pe.runtime, 3)} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textembeddings.get_table_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textembeddings.head().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"How do I do text chunking in SAP HANA?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myconn.sql(\n",
    "    f\"\"\"SELECT \n",
    "    COSINE_SIMILARITY(VECTOR_EMBEDDING('{prompt}', 'QUERY', 'SAP_GXY.20250407'), \"VECTOR_COL_CONTENT\") AS \"SIMILARITY\", \n",
    "    L2DISTANCE(VECTOR_EMBEDDING('What{prompt}', 'QUERY', 'SAP_GXY.20250407'), \"VECTOR_COL_CONTENT\") AS \"DISTANCE\", \n",
    "    \"ID\", \"SUB_ID\", \"CONTENT\" \n",
    "    FROM ({textembeddings.select_statement})\n",
    "    ORDER BY 1 DESC;\n",
    "    \"\"\"\n",
    ").collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
