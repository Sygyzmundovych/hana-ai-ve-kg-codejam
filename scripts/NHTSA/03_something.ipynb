{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the setup and connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../check_setup.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myconn.get_tables(schema='NHTSA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car complaints data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __National Highway Traffic Safety Administration (NHTSA)__, is part of the U.S. Department of Transportation.\n",
    "Complaint information entered into NHTSAâ€™s Office of Defects Investigation __vehicle owner's complaint database__ is used with other data sources to identify __safety issues__ that warrant investigation and to determine if a safety-related defect trend exists. Complaint information is also analyzed to monitor existing recalls for proper scope and adequacy. The NHTSA provides a large dataset of complaints related to cars in the US:[https://www.nhtsa.gov/nhtsa-datasets-and-apis#complaints].\n",
    "For this demo scenario, we've loaded the 2024 complaints data, for detail instructions see appendix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a HANA dataframe for the complaints data, pre-loaded into SAP HANA Cloud\n",
    "hdf_complaints=myconn.table('COMPLAINTS', schema='NHTSA')\n",
    "# hdf_complaints.get_table_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview the complaints data\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None) \n",
    "display(\n",
    "    hdf_complaints.filter(\"\"\"PROD_TYPE='V'\"\"\") # Vehicle-related complaint\n",
    "    .select('CMPLID', 'MAKETXT', 'MODELTXT', 'YEARTXT', 'COMPDESC', 'CDESCR')\n",
    "    .head(1).collect().T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's filter on specific component-groups, for detailed classification analysis\n",
    "hdf_carcomplaints=(hdf_complaints\n",
    "    .select('CMPLID', 'MFR_NAME', 'MAKETXT', 'MODELTXT', 'YEARTXT', 'FUEL_TYPE', 'CRASH', 'FIRE', 'STATE', 'CMPL_TYPE',\n",
    "            'ANTI_BRAKES_YN', 'CRUISE_CONT_YN', 'DRIVE_TRAIN', 'VEHICLES_TOWED_YN', 'CDESCR', 'COMPDESC')\n",
    "    .filter('''COMPDESC IN ('AIR BAGS','ELECTRICAL SYSTEM', 'SERVICE BRAKES','STEERING')'''))\n",
    "\n",
    "hdf_carcomplaints.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None) \n",
    "display(hdf_carcomplaints.head(1).collect().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text splitting, preparing complaints description text for vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text embedding models and Large Language Models (LLMs) often have token length limits, hence managing the text length before running it through such models is a frequent preprocessing task. For that purpose, a new text splitting function __hana_ml.text.text_splitter__ is being introduced and explained in more detail in the following blog post: [Text chunking - an exciting new NLP function in SAP HANA Cloud](https://community.sap.com/t5/technology-blogs-by-sap/text-chunking-an-exciting-new-nlp-function-in-sap-hana-cloud/ba-p/13958766)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the character length (using SQL length-fct) of a given text. For western languages, character-length / 3 or 4 is giving an approximate token length\n",
    "# Note, the text analysis function applied above, also determines the token length specifically\n",
    "\n",
    "hdf_carcomplaints.select('CMPLID', ('LENGTH(\"CDESCR\")', 'LEN_CDESCR')).sort('LEN_CDESCR', desc=True).head(100).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_carcomplaints.filter(\"\"\"CMPLID=1918524\"\"\").select(\"CDESCR\").collect().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the Text Splitter with recursive-splitting, available with hana-ml 2.23\n",
    "from hana_ml.text.text_splitter import TextSplitter\n",
    "\n",
    "splitter = TextSplitter(split_type='recursive', chunk_size=512, overlap=64)\n",
    "\n",
    "splitted_text = splitter.split_text(hdf_carcomplaints.select('CMPLID', 'CDESCR').head(10), order_status=True)\n",
    "#print(splitted_text.shape)\n",
    "display(splitter.statistics_.collect())\n",
    "\n",
    "display(splitted_text.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text Embeddings in SAP HANA Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAP HANA Cloud introduces availability of a text embedding model, targeted for vectorization of text data already stored within the database. It is specifically useful for vector engine similarity search scenarios or machine learning tasks, implicitly making use text embedding vectors unlocking the semantic understanding of text data for the analysis. A detailed capability introduction can be found in the following blog post [Text Embedding Service in SAP HANA Cloud Predictive Analysis Library (PAL)](https://community.sap.com/t5/enterprise-resource-planning-blogs-by-sap/text-embedding-service-in-sap-hana-cloud-predictive-analysis-library-pal/ba-p/13958864)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running vectorizations for 122447 recs took 37 minutes (2244 secs) on 4 vCPUs.\n",
    "\n",
    "For the sake of the exercise let's reduce the number of records by limiting only to cars with hubrid engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Number of records selected for further processing: {(hdf_carcomplaints_he := hdf_carcomplaints.filter(''' \"FUEL_TYPE\"='HE' ''')).count()}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating Text Embeddings in SAP HANA Cloud with the new PAL function, function available with hana-ml 2.23.\n",
    "from hana_ml.text.pal_embeddings import PALEmbeddings\n",
    "pe = PALEmbeddings()\n",
    "textembeddings = pe.fit_transform(hdf_carcomplaints_he, key=\"CMPLID\", target=[\"CDESCR\"], thread_number=10, batch_size=10) #, max_token_num=512\n",
    "print(f\"{textembeddings.count()} records processed in {round(pe.runtime, 3)} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textembeddings.get_table_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the generated Text Embeddings, note they are of vector dimensionality 768 for the current HANA embedding model\n",
    "cmpl_textembeddings=textembeddings.rename_columns({'VECTOR_COL_CDESCR': 'HANACLOUD_TEXT_EMBEDDING'}).to_tail('COMPDESC')\n",
    "display(cmpl_textembeddings.head(1).collect().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
