{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the setup and connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../01-check_setup.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myconn.get_tables(schema='NHTSA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car complaints data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __National Highway Traffic Safety Administration (NHTSA)__, is part of the U.S. Department of Transportation.\n",
    "Complaint information entered into NHTSA’s Office of Defects Investigation __vehicle owner's complaint database__ is used with other data sources to identify __safety issues__ that warrant investigation and to determine if a safety-related defect trend exists. Complaint information is also analyzed to monitor existing recalls for proper scope and adequacy. The NHTSA provides a large dataset of complaints related to cars in the US:[https://www.nhtsa.gov/nhtsa-datasets-and-apis#complaints].\n",
    "For this demo scenario, we've loaded the 2024 complaints data, for detail instructions see appendix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a HANA dataframe for the complaints data, pre-loaded into SAP HANA Cloud\n",
    "hdf_complaints=myconn.table('COMPLAINTS', schema='NHTSA')\n",
    "# hdf_complaints.get_table_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview the complaints data\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None) \n",
    "display(\n",
    "    hdf_complaints.filter(\"\"\"PROD_TYPE='V'\"\"\") # Vehicle-related complaint\n",
    "    .select('CMPLID', 'MAKETXT', 'MODELTXT', 'YEARTXT', 'COMPDESC', 'CDESCR')\n",
    "    .head(1).collect().T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's filter on specific component-groups, for detailed classification analysis\n",
    "hdf_carcomplaints=(hdf_complaints\n",
    "    .select('CMPLID', 'MFR_NAME', 'MAKETXT', 'MODELTXT', 'YEARTXT', 'FUEL_TYPE', 'CRASH', 'FIRE', 'STATE', 'CMPL_TYPE',\n",
    "            'ANTI_BRAKES_YN', 'CRUISE_CONT_YN', 'DRIVE_TRAIN', 'VEHICLES_TOWED_YN', 'CDESCR', 'COMPDESC')\n",
    "    .filter('''COMPDESC IN ('AIR BAGS','ELECTRICAL SYSTEM', 'SERVICE BRAKES','STEERING')'''))\n",
    "\n",
    "hdf_carcomplaints.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None) \n",
    "display(hdf_carcomplaints.head(1).collect().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text splitting, preparing complaints description text for vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text embedding models and Large Language Models (LLMs) often have token length limits, hence managing the text length before running it through such models is a frequent preprocessing task. For that purpose, a new text splitting function __hana_ml.text.text_splitter__ is being introduced and explained in more detail in the following blog post: [Text chunking - an exciting new NLP function in SAP HANA Cloud](https://community.sap.com/t5/technology-blogs-by-sap/text-chunking-an-exciting-new-nlp-function-in-sap-hana-cloud/ba-p/13958766)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the character length (using SQL length-fct) of a given text. For western languages, character-length / 3 or 4 is giving an approximate token length\n",
    "# Note, the text analysis function applied above, also determines the token length specifically\n",
    "\n",
    "hdf_carcomplaints.select('CMPLID', ('LENGTH(\"CDESCR\")', 'LEN_CDESCR')).sort('LEN_CDESCR', desc=True).head(100).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_carcomplaints.filter(\"\"\"CMPLID=1918524\"\"\").select(\"CDESCR\").collect().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the Text Splitter with recursive-splitting, available with hana-ml 2.23\n",
    "from hana_ml.text.text_splitter import TextSplitter\n",
    "\n",
    "splitter = TextSplitter(split_type='recursive', chunk_size=512, overlap=64)\n",
    "splitter._extend_pal_parameter({'GLOBAL_SEPARATOR':'[.]', 'KEEP_SEPARATOR':1})\n",
    "splitted_text = splitter.split_text(\n",
    "    hdf_carcomplaints.filter(\"LENGTH(CDESCR)>=512\").select('CMPLID', 'CDESCR').head(10), \n",
    "    order_status=True\n",
    "    )\n",
    "#print(splitted_text.shape)\n",
    "display(splitter.statistics_.collect())\n",
    "\n",
    "display(splitted_text.select(\"*\", ('LENGTH(\"CONTENT\")', \"CHUNK_SIZE\")).head(15).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text Embeddings in SAP HANA Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAP HANA Cloud introduces availability of a text embedding model, targeted for vectorization of text data already stored within the database. It is specifically useful for vector engine similarity search scenarios or machine learning tasks, implicitly making use text embedding vectors unlocking the semantic understanding of text data for the analysis. A detailed capability introduction can be found in the following blog post [Text Embedding Service in SAP HANA Cloud Predictive Analysis Library (PAL)](https://community.sap.com/t5/enterprise-resource-planning-blogs-by-sap/text-embedding-service-in-sap-hana-cloud-predictive-analysis-library-pal/ba-p/13958864)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running vectorizations for 122447 recs took 37 minutes (2244 secs) on 4 vCPUs.\n",
    "\n",
    "For the sake of the exercise let's reduce the number of records by limiting only to cars with hybrid engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Number of records selected for further processing: {(hdf_carcomplaints_he := hdf_carcomplaints.filter(''' \"FUEL_TYPE\"='HE' ''')).count()}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating Text Embeddings in SAP HANA Cloud with the new PAL function, function available with hana-ml 2.23.\n",
    "from hana_ml.text.pal_embeddings import PALEmbeddings\n",
    "pe = PALEmbeddings(model_version='SAP_GXY.20250407')\n",
    "textembeddings = pe.fit_transform(hdf_carcomplaints_he, key=\"CMPLID\", target=[\"CDESCR\"], thread_number=10, batch_size=10) #, max_token_num=512\n",
    "print(f\"{textembeddings.count()} records processed in {round(pe.runtime, 3)} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textembeddings.get_table_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the generated Text Embeddings, note they are of vector dimensionality 768 for the current HANA embedding model\n",
    "cmpl_textembeddings=textembeddings.rename_columns({'VECTOR_COL_CDESCR': 'HANACLOUD_TEXT_EMBEDDING'}).to_tail('COMPDESC')\n",
    "display(cmpl_textembeddings.head(1).collect().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Embeddings for Advanced Text Mining using ANNS (Approximate Nearest Neighbor Search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New text mining techniques can now be applied leveraging existing text embedding vectors (or create them implicitly from the original text) unlocking the semantic understanding of text data for text mining tasks like text document classification. Thus elevating a classic task from linguistic text understanding to understanding the real natural language context of documents for greatly improved results. This new technique in SAP HANA Cloud Predictive Analysis Library for advanced text mining builds on the concept of approximate neares neighbor search, thus also adressing larger scale scenarios. The advanced text mining function is explained with more detail in the following blog post [New information retrieval techniques in SAP HANA Cloud using BM25 and ANNS for Advanced Text Mining](https://community.sap.com/t5/technology-blogs-by-sap/new-information-retrieval-techniques-in-sap-hana-cloud-using-bm25-and-anns/ba-p/13958729)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_carcomplaints.filter('''MFR_NAME LIKE ('Tesla%')''').agg([('count', 'YEARTXT', 'COUNT')], group_by='YEARTXT').sort(cols='YEARTXT', desc=False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the input dataframe for ANNS-advanced text mining\n",
    "# Required input data schema: document-id, text\n",
    "carcomplaints_anns_hdf=hdf_carcomplaints.filter('''MFR_NAME LIKE ('Tesla%') AND \"YEARTXT\"='2022' ''').select('CMPLID', 'CDESCR')\n",
    "display(carcomplaints_anns_hdf.head(1).collect())\n",
    "display(carcomplaints_anns_hdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the ANNS-advanced text mining model\n",
    "# Note, the complaints shall be clustered into 70 groups for the approximate similarity search\n",
    "from hana_ml.text.anns_model import ANNSModel\n",
    "\n",
    "anns = ANNSModel(by_doc=True)\n",
    "anns.fit(data=carcomplaints_anns_hdf, key='CMPLID', target='CDESCR', group_number=70, max_iteration=100, \n",
    "         comment='TESLA complaints search model for 2022')\n",
    "\n",
    "print(f\"Runtime building the ANN-text mining search model：{anns.runtime} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing the implicit embedding generation results from the ANNS-advanced text mining model building\n",
    "print(anns.embedding_result_.shape)\n",
    "display(anns.embedding_result_.head(1).collect().T)\n",
    "print(f\"\"\"Vector cardinality: {anns.embedding_result_.head(1).select((\"CARDINALITY(VECTOR_COL)\",\"A\")).collect()[\"A\"][0]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ANNS-advanced text mining model is kept as a stateful in-memory model for fastest search predictions\n",
    "display(anns.state_.collect().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, search for CDESCR complaints with the search text: '12v battery is empty'\n",
    "# Prepare the search query dataframe as: Searchquery-Id, text\n",
    "hdf_anns_query=myconn.sql(\n",
    "    '''Select '999' as \"QID\", 'battery exploded' as \"SEARCHTEXT\" from \"DUMMY\"\n",
    "    UNION ALL\n",
    "    Select '998' as \"QID\", '12v battery empty' as \"SEARCHTEXT\" from \"DUMMY\"'''\n",
    "    )\n",
    "hdf_anns_query.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the adv. text mining / ANN search \n",
    "res = anns.predict(data=hdf_anns_query, key='QID', target='SEARCHTEXT', is_query=True, k_nearest_neighbours=3, k_cluster=70) \n",
    "print(f\"Runtime ：{anns.runtime} s\") \n",
    "display(res.collect()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the adv.text mining/ann search results with the original CDESCR-text\n",
    "anns_top_searchresults=(\n",
    "    res.rename_columns({'TEST_QID': 'QID'})\n",
    "    .set_index(\"TRAIN_ID\")\n",
    "    .join(carcomplaints_anns_hdf.set_index(\"CMPLID\"))\n",
    "    )\n",
    "display(anns_top_searchresults.rename_columns({'TRAIN_ID': 'CMPLID'}).sort('DISTANCE').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the stateful Adv.text mining/ANNS-models on the system\n",
    "from hana_ml.text.anns_model import list_models\n",
    "list_models(myconn).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete last <anns-object>-model instance\n",
    "anns.delete_model().collect().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the stateful Adv.text mining/ANNS-models on the system, again\n",
    "annsmodelstodelete=list_models(myconn)\n",
    "annsmodelstodelete.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
