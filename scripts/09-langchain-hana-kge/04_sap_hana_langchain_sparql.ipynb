{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f46bd472-9a41-4cdd-ab40-7ebfb4e2aa87",
   "metadata": {},
   "source": [
    "# SAP HANA Cloud Knowledge Graph Engine\n",
    "\n",
    ">[SAP HANA Cloud Knowledge Graph](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-knowledge-graph-guide/sap-hana-cloud-sap-hana-database-knowledge-graph-engine-guide) is a fully integrated knowledge graph solution within the `SAP HANA Cloud` database.\n",
    ">\n",
    ">This example demonstrates how to build a QA (Question-Answering) chain that queries [Resource Description Framework (RDF)](https://en.wikipedia.org/wiki/Resource_Description_Framework) data stored in an `SAP HANA Cloud` instance using the `SPARQL` query language, and returns a human-readable response.\n",
    ">\n",
    ">[SPARQL](https://en.wikipedia.org/wiki/SPARQL) is the standard query language for querying `RDF` graphs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ad465-8e62-49b5-81c7-3e98d6e85e53",
   "metadata": {},
   "source": [
    "## Setup & Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e4c74-5818-4347-9f3d-d63202ae68e5",
   "metadata": {},
   "source": [
    "**Prerequisite**:  \n",
    "You must have an SAP HANA Cloud instance with the **triple store** feature enabled.  \n",
    "For detailed instructions, refer to: [Enable Triple Store](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-knowledge-graph-guide/enable-triple-store/)<br />\n",
    "Load the `kgdocu_movies` example data. See [Knowledge Graph Example](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-knowledge-graph-guide/knowledge-graph-example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c519a33-b21d-4a45-a6a9-b1538da40751",
   "metadata": {},
   "source": [
    "To use SAP HANA Knowledge Graph Engine and/or Vector Store Engine with LangChain, install the `langchain-hana` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8234ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_hana\n",
    "print(langchain_hana.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc3e3fb-9fad-464e-a68a-f49cb3da31bd",
   "metadata": {},
   "source": [
    "First, create a connection to your SAP HANA Cloud instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452fedb4-e121-41bd-92de-ae211d2bf928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from hdbcli import dbapi\n",
    "\n",
    "# Load environment variables if needed\n",
    "load_dotenv()\n",
    "\n",
    "# Establish connection to SAP HANA Cloud\n",
    "connection = dbapi.connect(\n",
    "    address=os.environ.get(\"HANADB_URL\"),\n",
    "    port=os.environ.get(\"HANADB_PRT\"),\n",
    "    user=os.environ.get(\"HANADB_USR\"),\n",
    "    password=os.environ.get(\"HANADB_PWD\"),\n",
    "    autocommit=True,\n",
    "    sslValidateCertificate=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cdf946",
   "metadata": {},
   "source": [
    "## Initialize the `HanaRdfGraph`\n",
    "\n",
    "You need a `HanaRdfGraph` instance that:\n",
    "\n",
    "1. Loads your ontology schema (in Turtle)  \n",
    "2. Executes SPARQL queries against your SAP HANA Cloud data graph  \n",
    "\n",
    "The constructor requires:\n",
    "\n",
    "- **`connection`**: an active `hdbcli.dbapi.connect(...)` instance  \n",
    "- **`graph_uri`**: the named graph (or `\"DEFAULT\"`) where your RDF data lives  \n",
    "- **One of**:  \n",
    "  1. `ontology_query`**: a SPARQL CONSTRUCT to extract schema triples  \n",
    "  2. `ontology_uri`**: a hosted ontology graph URI  \n",
    "  3. `ontology_local_file`** + **`ontology_local_file_format`**: a local Turtle/RDF file  \n",
    "  4. `auto_extract_ontology=True`** (not recommended for production—see note)\n",
    "\n",
    "`graph_uri` vs. Ontology\n",
    "- **`graph_uri`**:  \n",
    "  The named graph in your SAP HANA Cloud instance that contains your instance data (sometimes 100k+ triples).\n",
    "  If `None` or `\"DEFAULT\"` is provided, the default graph is used.  \n",
    "  ➔ More details: [Default Graph and Named Graphs](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-knowledge-graph-guide/default-graph-and-named-graphs)\n",
    "- **Ontology**: a lean schema (typically ~50-100 triples) describing classes, properties, domains, ranges, labels, comments, and subclass relationships. The ontology guides SPARQL generation and result interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e51f87a-ffe1-464b-874e-297fe5dd4547",
   "metadata": {},
   "source": [
    "## Example: Question Answering over a “Movies” Knowledge Graph\n",
    "\n",
    "Below we’ll:\n",
    "\n",
    "1. Instantiate the `HanaRdfGraph` pointing at our “movies” data graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba3dd8-2786-4157-9db5-901ffa3d89d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_hana import HanaRdfGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e0e4c-e242-42f5-b117-83ce9db0e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Knowledge Graph\n",
    "graph_uri = \"kgdocu_movies\"\n",
    "\n",
    "graph = HanaRdfGraph(\n",
    "    connection=connection, graph_uri=graph_uri, auto_extract_ontology=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daab00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a basic graph schema is extracted from the data graph. This schema will guide the LLM to generate a proper SPARQL query.\n",
    "print(graph.get_schema)\n",
    "schema_ttl = graph.get_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a0d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "from rdflib.tools.rdf2dot import rdf2dot\n",
    "import io\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fbb66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse into an RDFLib graph\n",
    "g = rdflib.Graph()\n",
    "g.parse(data=graph.get_schema, format=\"turtle\")\n",
    "\n",
    "# Build a NetworkX graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add edges based on domain-range relationships\n",
    "for prop in g.subjects(rdflib.RDF.type, rdflib.OWL.ObjectProperty):\n",
    "    domain = g.value(prop, rdflib.RDFS.domain)\n",
    "    range_ = g.value(prop, rdflib.RDFS.range)\n",
    "    label = g.value(prop, rdflib.RDFS.label) or prop.split('/')[-1]\n",
    "    if domain and range_:\n",
    "        d_label = domain.split('/')[-1]\n",
    "        r_label = range_.split('/')[-1]\n",
    "        G.add_node(d_label)\n",
    "        G.add_node(r_label)\n",
    "        G.add_edge(d_label, r_label, label=str(label))\n",
    "\n",
    "for prop in g.subjects(rdflib.RDF.type, rdflib.OWL.DatatypeProperty):\n",
    "    domain = g.value(prop, rdflib.RDFS.domain)\n",
    "    range_ = g.value(prop, rdflib.RDFS.range)\n",
    "    label = g.value(prop, rdflib.RDFS.label) or prop.split('/')[-1]\n",
    "    if domain and range_:\n",
    "        d_label = domain.split('/')[-1]\n",
    "        r_label = range_.split('/')[-1]\n",
    "        G.add_node(d_label)\n",
    "        G.add_node(r_label)\n",
    "        G.add_edge(d_label, r_label, label=str(label))\n",
    "\n",
    "# Draw using Matplotlib\n",
    "# pos = nx.spring_layout(G)\n",
    "# pos = nx.kamada_kawai_layout(G, weight=None)\n",
    "pos = nx.circular_layout(G)\n",
    "# pos = nx.spectral_layout(G)\n",
    "\n",
    "nx.draw(G, pos, with_labels=True, node_size=2000)\n",
    "edge_labels = nx.get_edge_attributes(G, 'label')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "plt.title(\"Ontology Schema Graph\")\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d79e0f",
   "metadata": {},
   "source": [
    "## Executing SPARQL Queries\n",
    "\n",
    "You can use the `query()` method to execute arbitrary SPARQL queries (`SELECT`, `ASK`, `CONSTRUCT`, etc.) on the data graph.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e944500",
   "metadata": {},
   "source": [
    "The following query retrieves the top 10 movies with the highest number of contributors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a266c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "PREFIX kg: <http://kg.demo.sap.com/>\n",
    "SELECT ?movieTitle (COUNT(?actor) AS ?actorCount)\n",
    "\n",
    "FROM <kgdocu_movies>\n",
    "WHERE {\n",
    "    ?actor kg:acted_in ?movie .\n",
    "    ?movie kg:title ?movieTitle .\n",
    "}\n",
    "GROUP BY ?movieTitle\n",
    "ORDER BY DESC(?actorCount)\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "top10 = graph.query(query)\n",
    "pd.read_csv(io.StringIO(top10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
