{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requires [`conda` environment](https://docs.anaconda.com/miniconda/install/#quickstart-install-instructions), because `pip install` of `gensim` is failing in build phase on BAS:\n",
    "```shell\n",
    "mkdir -p ~/miniconda3\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n",
    "bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n",
    "rm ~/miniconda3/miniconda.sh\n",
    "source ~/miniconda3/bin/activate\n",
    "conda create -n gensim  -c conda-forge python=3.11 \n",
    "conda activate gensim\n",
    "conda install -c conda-forge tensorflow-cpu ipykernel pillow pandas gensim\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Vectors trained on the Google News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import downloader, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the details of the word vevtors model 'word2vec-google-news-300' available in [GenSim](https://radimrehurek.com/gensim/intro.html#what-is-gensim).\n",
    "\n",
    "It was trained on Google News using about 100 billion words. You can see it stores vectors for 3 million different tokens (words, phrases, parts of words), and it's raw size is quite big: 1.7GB compressed with gzip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_records': 3000000,\n",
       " 'file_size': 1743563840,\n",
       " 'base_dataset': 'Google News (about 100 billion words)',\n",
       " 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/word2vec-google-news-300/__init__.py',\n",
       " 'license': 'not found',\n",
       " 'parameters': {'dimension': 300},\n",
       " 'description': \"Pre-trained vectors trained on a part of the Google News dataset (about 100 billion words). The model contains 300-dimensional vectors for 3 million words and phrases. The phrases were obtained using a simple data-driven approach described in 'Distributed Representations of Words and Phrases and their Compositionality' (https://code.google.com/archive/p/word2vec/).\",\n",
       " 'read_more': ['https://code.google.com/archive/p/word2vec/',\n",
       "  'https://arxiv.org/abs/1301.3781',\n",
       "  'https://arxiv.org/abs/1310.4546',\n",
       "  'https://www.microsoft.com/en-us/research/publication/linguistic-regularities-in-continuous-space-word-representations/?from=http%3A%2F%2Fresearch.microsoft.com%2Fpubs%2F189726%2Frvecs.pdf'],\n",
       " 'checksum': 'a5e5354d40acb95f9ec66d5977d140ef',\n",
       " 'file_name': 'word2vec-google-news-300.gz',\n",
       " 'parts': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloader.info('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the bandwith of your network it should take about 1-4 minutes to download 1.7GB files with the model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
      "CPU times: user 44.6 s, sys: 24.8 s, total: 1min 9s\n",
      "Wall time: 58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mymodel_path = downloader.load('word2vec-google-news-300', return_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n"
     ]
    }
   ],
   "source": [
    "print(mymodel_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise you are not going to load all 3 million records, as it takes too long and might stretch the capacity of your trial account.\n",
    "\n",
    "Therefore you can set `mylimit_size` to 100000 to practice; this is sufficient. Loading all 3000000 would take about 6 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylimit_size=3000000\n",
    "mymodel_path='/home/user/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'\n",
    "mymodel = models.KeyedVectors.load_word2vec_format(mymodel_path, binary=True, limit=mylimit_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the model to be loaded into SAP HANA db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should take about 20 seconds to convert the 100K records of data from the model to the Python list that you can load into the SAP HANA db instance. It should take about 5 minutes for the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n",
      "CPU times: user 4min 42s, sys: 50 s, total: 5min 32s\n",
      "Wall time: 5min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "myrecords=list()\n",
    "\n",
    "for index, word in enumerate(mymodel.index_to_key):\n",
    "    myrecord=(index, word, str(mymodel[word].tolist()))\n",
    "    myrecords.append(myrecord)\n",
    "\n",
    "print(len(myrecords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# # Open a file in binary write mode\n",
    "with open('/tmp/myrecords.pkl', 'wb') as file:\n",
    "    # Serialize the list and write it to the file\n",
    "    pickle.dump(myrecords, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Switch to virtual env now to load to HANA db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Open the file in binary read mode\n",
    "with open('/tmp/myrecords.pkl', 'rb') as file:\n",
    "    # Deserialize the list from the file\n",
    "    myrecords = pickle.load(file)\n",
    "\n",
    "print(len(myrecords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model into SAP HANA's Vector Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAP HANA Client for Python: 2.26.25111700\n",
      "Connected to SAP HANA db version 4.00.000.00.1764669230 (fa/CE2025.28) \n",
      "at c5889dd5-e0f6-4930-8408-94d53ca61dbf.hna0.prod-us10.hanacloud.ondemand.com:443 as CODEJAMHANAAI00\n",
      "Current time on the SAP HANA server: 2025-12-12 21:15:04.498000\n"
     ]
    }
   ],
   "source": [
    "%run \"../01-check_setup.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statement below will drop the database table `\"GOOGLE_NEWS\"`, if it exists already! \n",
    "\n",
    "If this table does not exist, then it will return just an error message, like `An error occurred: 'invalid table name: GOOGLE_NEWS ...'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: (259, 'invalid table name: GOOGLE_NEWS: line 1 col 22 (at pos 21)')\n"
     ]
    }
   ],
   "source": [
    "myconn.connection.setautocommit(True)\n",
    "mycursor = myconn.connection.cursor()\n",
    "\n",
    "try:\n",
    "    mycursor.execute('DROP TABLE \"VECTORS\".\"GOOGLE_NEWS\"')\n",
    "    myconn.connection.commit()\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any exceptions and possibly rollback the transaction\n",
    "    myconn.connection.rollback()\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use hana-ml package's method `create_table()` to create a physical table in your SAP HANA db instance. Please note the use of the data type [`REAL_VECTOR(300)`](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/real-vector-data-type) available in SAP HANA database in SAP HANA Cloud starting with the 2024/Q1 release.\n",
    "\n",
    "`300` is the dimnsionality of the vectors to be stored in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myconn.create_table(\n",
    "    \"GOOGLE_NEWS\", \n",
    "    schema=\"VECTORS\",\n",
    "    table_structure={\n",
    "        \"ID\":\"INT\", \n",
    "        \"WORD\":\"NVARCHAR(5000)\", \n",
    "        \"WV\": \"REAL_VECTOR(300)\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see `GOOGLE_NEWS` table name returned below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABLE_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGLE_NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMAGES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TABLE_NAME\n",
       "0  GOOGLE_NEWS\n",
       "1       IMAGES"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myconn.get_tables(schema=\"VECTORS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [`executemany` method](https://help.sap.com/docs/SAP_HANA_CLIENT/f1b440ded6144a54ada97ff95dac7adf/15e46b843c8045ec854d6375790cd504.html) from the SAP HANA Client Interface to insert records from the Python list onject into SAP HANA database table.\n",
    "\n",
    "It might take up to 20 minutes for all 3000000 records to be inserted, but only about 10 seconds for 100000 records."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "%%time\n",
    "myconn.connection.setautocommit(False)\n",
    "mycursor = myconn.connection.cursor()\n",
    "\n",
    "try:\n",
    "    mycursor.execute('TRUNCATE TABLE \"VECTORS\".\"GOOGLE_NEWS\"')\n",
    "    # Use the executemany method to insert the data\n",
    "    mycursor.executemany(\n",
    "        operation = '''INSERT INTO \"VECTORS\".\"GOOGLE_NEWS\"(\"ID\", \"WORD\", \"WV\") VALUES (?, ?, TO_REAL_VECTOR(?))''', \n",
    "        list_of_parameters = myrecords\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any exceptions and possibly rollback the transaction\n",
    "    myconn.connection.rollback()\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 (100000 rows) ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in 10.79 seconds\n",
      "Chunk 2 (100000 rows) ... in 7.71 seconds\n",
      "Chunk 3 (100000 rows) ... in 8.29 seconds\n",
      "Chunk 4 (100000 rows) ... in 8.44 seconds\n",
      "Chunk 5 (100000 rows) ... in 8.84 seconds\n",
      "Chunk 6 (100000 rows) ... in 8.96 seconds\n",
      "Chunk 7 (100000 rows) ... in 9.34 seconds\n",
      "Chunk 8 (100000 rows) ... in 9.90 seconds\n",
      "Chunk 9 (100000 rows) ... in 9.24 seconds\n",
      "Chunk 10 (100000 rows) ... in 9.24 seconds\n",
      "Chunk 11 (100000 rows) ... in 8.86 seconds\n",
      "Chunk 12 (100000 rows) ... in 9.03 seconds\n",
      "Chunk 13 (100000 rows) ... in 10.06 seconds\n",
      "Chunk 14 (100000 rows) ... in 9.98 seconds\n",
      "Chunk 15 (100000 rows) ... in 9.98 seconds\n",
      "Chunk 16 (100000 rows) ... in 10.13 seconds\n",
      "Chunk 17 (100000 rows) ... in 9.95 seconds\n",
      "Chunk 18 (100000 rows) ... in 9.81 seconds\n",
      "Chunk 19 (100000 rows) ... in 9.68 seconds\n",
      "Chunk 20 (100000 rows) ... in 10.05 seconds\n",
      "Chunk 21 (100000 rows) ... in 9.99 seconds\n",
      "Chunk 22 (100000 rows) ... in 9.52 seconds\n",
      "Chunk 23 (100000 rows) ... in 9.39 seconds\n",
      "Chunk 24 (100000 rows) ... in 9.87 seconds\n",
      "Chunk 25 (100000 rows) ... in 9.46 seconds\n",
      "Chunk 26 (100000 rows) ... in 9.80 seconds\n",
      "Chunk 27 (100000 rows) ... in 10.21 seconds\n",
      "Chunk 28 (100000 rows) ... in 9.87 seconds\n",
      "Chunk 29 (100000 rows) ... in 9.53 seconds\n",
      "Chunk 30 (100000 rows) ... in 9.39 seconds\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "# --- Config ---\n",
    "num_parts = 30                    # how many chunks to split into\n",
    "parts_to_load = range(1, 31)      # which 1-based parts to load (e.g., range(5, 11) for parts 5..10)\n",
    "\n",
    "# --- Setup ---\n",
    "myconn.connection.setautocommit(False)\n",
    "mycursor = myconn.connection.cursor()\n",
    "\n",
    "# Truncate only if part 1 is being loaded\n",
    "if 1 in parts_to_load:\n",
    "    try:\n",
    "        mycursor.execute('TRUNCATE TABLE \"VECTORS\".\"GOOGLE_NEWS\"')\n",
    "        myconn.connection.commit()\n",
    "    except Exception as e:\n",
    "        myconn.connection.rollback()\n",
    "        raise RuntimeError(f\"Failed to truncate table: {e}\") from e\n",
    "\n",
    "# --- Insert in chunks ---\n",
    "total = len(myrecords)\n",
    "chunk_size = math.ceil(total / num_parts) if num_parts > 0 else total\n",
    "\n",
    "for part_idx_1based in range(1, num_parts + 1):\n",
    "    if part_idx_1based not in parts_to_load:\n",
    "        continue\n",
    "\n",
    "    start = (part_idx_1based - 1) * chunk_size\n",
    "    end = min(start + chunk_size, total)\n",
    "    chunk = myrecords[start:end]\n",
    "\n",
    "    if not chunk:\n",
    "        continue  # nothing in this part (can happen if num_parts > needed)\n",
    "\n",
    "    try:\n",
    "        print(f\"Chunk {part_idx_1based} ({len(chunk)} rows) ...\", end=\"\", flush=True)\n",
    "        t0 = time.time()\n",
    "\n",
    "        mycursor.executemany(\n",
    "            operation='''INSERT INTO \"VECTORS\".\"GOOGLE_NEWS\"(\"ID\", \"WORD\", \"WV\") \n",
    "                         VALUES (?, ?, TO_REAL_VECTOR(?))''',\n",
    "            list_of_parameters=chunk\n",
    "        )\n",
    "        myconn.connection.commit()\n",
    "\n",
    "        elapsed = time.time() - t0\n",
    "        print(f\" in {elapsed:.2f} seconds\")\n",
    "    except Exception as e:\n",
    "        myconn.connection.rollback()\n",
    "        raise RuntimeError(\n",
    "            f\"Error in part {part_idx_1based} (rows {start}:{end}): {e}\"\n",
    "        ) from e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that the statement above is not commiting the transaction and records are not visible for other processes in the database table unless the below connection commit is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 525 μs, sys: 792 μs, total: 1.32 ms\n",
      "Wall time: 2.09 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    # Commit the transaction to save the changes\n",
    "    myconn.connection.commit()\n",
    "\n",
    "finally:\n",
    "    # Close the cursor and the connection when done\n",
    "    mycursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.18 ms, sys: 1.29 ms, total: 9.47 ms\n",
      "Wall time: 8min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mycursor = myconn.connection.cursor()\n",
    "\n",
    "try:\n",
    "    mycursor.execute('CREATE HNSW VECTOR INDEX CSIDX ON \"VECTORS\".\"GOOGLE_NEWS\" (\"WV\") SIMILARITY FUNCTION COSINE_SIMILARITY ')\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any exceptions and possibly rollback the transaction\n",
    "    myconn.connection.rollback()\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHEMA_NAME</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>INDEX_TYPE</th>\n",
       "      <th>INDEX_NAME</th>\n",
       "      <th>SIMILARITY_FUNCTION</th>\n",
       "      <th>BUILD_CONFIGURATION</th>\n",
       "      <th>SEARCH_CONFIGURATION</th>\n",
       "      <th>CREATE_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SCHEMA_NAME, TABLE_NAME, COLUMN_NAME, INDEX_TYPE, INDEX_NAME, SIMILARITY_FUNCTION, BUILD_CONFIGURATION, SEARCH_CONFIGURATION, CREATE_TIME]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myconn.table(\"VECTOR_INDEXES\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check tha data in the database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myconn.table(\"GOOGLE_NEWS\", schema=\"VECTORS\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statement below will return a preview of a few records with the preview of their vector value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>WORD</th>\n",
       "      <th>WORD_VECTOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2043</td>\n",
       "      <td>dog</td>\n",
       "      <td>[0.05126953,-0.022338867,-0.17285156,0.1611328...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9760</td>\n",
       "      <td>Dog</td>\n",
       "      <td>[-0.24609375,0.0000123381615,-0.17285156,0.240...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93909</td>\n",
       "      <td>DOG</td>\n",
       "      <td>[-0.114746094,-0.24023438,0.083496094,0.237304...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID WORD                                        WORD_VECTOR\n",
       "0   2043  dog  [0.05126953,-0.022338867,-0.17285156,0.1611328...\n",
       "1   9760  Dog  [-0.24609375,0.0000123381615,-0.17285156,0.240...\n",
       "2  93909  DOG  [-0.114746094,-0.24023438,0.083496094,0.237304..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    myconn\n",
    "    .table(\"GOOGLE_NEWS\", schema=\"VECTORS\")\n",
    "    .filter(\"UPPER(WORD) LIKE 'DOG'\")\n",
    "    .select('ID', 'WORD', ('TO_NVARCHAR(WV)',\"WORD_VECTOR\"))\n",
    "    .head(3)\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the vector representation of the word **dog**.\n",
    "\n",
    "Note the use of the [`TO_NVARCHAR()` SQL function](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/to-nvarchar-function-data-type-conversion) to display the numerical (and not binary) values of the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05126953,\n",
       " -0.022338867,\n",
       " -0.17285156,\n",
       " 0.16113281,\n",
       " -0.084472656,\n",
       " 0.057373047,\n",
       " 0.05859375,\n",
       " -0.08251953,\n",
       " -0.015380859,\n",
       " -0.06347656,\n",
       " 0.1796875,\n",
       " -0.42382812,\n",
       " -0.022583008,\n",
       " -0.16601562,\n",
       " -0.025146484,\n",
       " 0.107421875,\n",
       " -0.19921875,\n",
       " 0.15917969,\n",
       " -0.1875,\n",
       " -0.12011719,\n",
       " 0.15527344,\n",
       " -0.099121094,\n",
       " 0.14257812,\n",
       " -0.1640625,\n",
       " -0.08935547,\n",
       " 0.20019531,\n",
       " -0.14941406,\n",
       " 0.3203125,\n",
       " 0.328125,\n",
       " 0.024414062,\n",
       " -0.09716797,\n",
       " -0.08203125,\n",
       " -0.036376953,\n",
       " -0.0859375,\n",
       " -0.09863281,\n",
       " 0.0077819824,\n",
       " -0.013427734,\n",
       " 0.052734375,\n",
       " 0.1484375,\n",
       " 0.33398438,\n",
       " 0.016601562,\n",
       " -0.21289062,\n",
       " -0.015075684,\n",
       " 0.052490234,\n",
       " -0.107421875,\n",
       " -0.08886719,\n",
       " 0.24902344,\n",
       " -0.0703125,\n",
       " -0.015991211,\n",
       " 0.075683594,\n",
       " -0.0703125,\n",
       " 0.119140625,\n",
       " 0.22949219,\n",
       " 0.014160156,\n",
       " 0.115234375,\n",
       " 0.007507324,\n",
       " 0.27539062,\n",
       " -0.24414062,\n",
       " 0.296875,\n",
       " 0.03491211,\n",
       " 0.2421875,\n",
       " 0.13574219,\n",
       " 0.14257812,\n",
       " 0.017578125,\n",
       " 0.029296875,\n",
       " -0.12158203,\n",
       " 0.022827148,\n",
       " -0.047607422,\n",
       " -0.15527344,\n",
       " 0.0031433105,\n",
       " 0.34570312,\n",
       " 0.122558594,\n",
       " -0.1953125,\n",
       " 0.08105469,\n",
       " -0.068359375,\n",
       " -0.014709473,\n",
       " 0.21484375,\n",
       " -0.12109375,\n",
       " 0.15722656,\n",
       " -0.20703125,\n",
       " 0.13671875,\n",
       " -0.12988281,\n",
       " 0.052978516,\n",
       " -0.27148438,\n",
       " -0.29882812,\n",
       " -0.18457031,\n",
       " -0.22949219,\n",
       " 0.119140625,\n",
       " 0.015319824,\n",
       " -0.26171875,\n",
       " -0.123046875,\n",
       " -0.018676758,\n",
       " -0.064941406,\n",
       " -0.08154297,\n",
       " 0.07861328,\n",
       " -0.35351562,\n",
       " 0.052490234,\n",
       " -0.024536133,\n",
       " -0.005432129,\n",
       " -0.20898438,\n",
       " -0.2109375,\n",
       " -0.1796875,\n",
       " 0.2421875,\n",
       " 0.2578125,\n",
       " 0.13769531,\n",
       " -0.2109375,\n",
       " -0.021728516,\n",
       " -0.13867188,\n",
       " 0.018432617,\n",
       " -0.012390137,\n",
       " -0.15917969,\n",
       " 0.16113281,\n",
       " 0.20800781,\n",
       " 0.103027344,\n",
       " 0.09814453,\n",
       " -0.068359375,\n",
       " -0.008728027,\n",
       " -0.2890625,\n",
       " -0.21484375,\n",
       " -0.11425781,\n",
       " -0.22167969,\n",
       " 0.041259766,\n",
       " -0.3125,\n",
       " -0.055908203,\n",
       " -0.09765625,\n",
       " 0.05810547,\n",
       " -0.040527344,\n",
       " -0.17382812,\n",
       " 0.1640625,\n",
       " -0.25390625,\n",
       " -0.15429688,\n",
       " -0.02319336,\n",
       " -0.23828125,\n",
       " 0.020751953,\n",
       " -0.2734375,\n",
       " 0.00390625,\n",
       " 0.11376953,\n",
       " -0.17382812,\n",
       " 0.2578125,\n",
       " 0.23535156,\n",
       " 0.052246094,\n",
       " 0.068359375,\n",
       " -0.17578125,\n",
       " 0.16015625,\n",
       " -0.00059890747,\n",
       " 0.059814453,\n",
       " -0.21191406,\n",
       " -0.055419922,\n",
       " -0.07519531,\n",
       " -0.30664062,\n",
       " 0.42773438,\n",
       " 0.053222656,\n",
       " -0.20898438,\n",
       " -0.057128906,\n",
       " -0.20996094,\n",
       " 0.032958984,\n",
       " 0.10546875,\n",
       " -0.15039062,\n",
       " -0.09375,\n",
       " 0.11669922,\n",
       " 0.064453125,\n",
       " 0.028076172,\n",
       " 0.24121094,\n",
       " -0.12597656,\n",
       " -0.10058594,\n",
       " -0.012268066,\n",
       " -0.00032615662,\n",
       " 0.01586914,\n",
       " 0.12792969,\n",
       " -0.033203125,\n",
       " 0.040771484,\n",
       " -0.13183594,\n",
       " 0.09814453,\n",
       " 0.17480469,\n",
       " -0.23632812,\n",
       " 0.051757812,\n",
       " 0.18359375,\n",
       " 0.024291992,\n",
       " -0.43164062,\n",
       " 0.24609375,\n",
       " -0.030395508,\n",
       " -0.024780273,\n",
       " -0.1171875,\n",
       " 0.16113281,\n",
       " -0.057128906,\n",
       " 0.011657715,\n",
       " 0.28125,\n",
       " 0.42773438,\n",
       " 0.045654297,\n",
       " 0.10107422,\n",
       " -0.03955078,\n",
       " 0.017700195,\n",
       " -0.08984375,\n",
       " 0.13574219,\n",
       " 0.20800781,\n",
       " 0.18847656,\n",
       " -0.15234375,\n",
       " -0.23730469,\n",
       " -0.19042969,\n",
       " 0.07128906,\n",
       " -0.24609375,\n",
       " -0.26171875,\n",
       " -0.234375,\n",
       " -0.14550781,\n",
       " -0.01171875,\n",
       " -0.15039062,\n",
       " -0.11328125,\n",
       " 0.18261719,\n",
       " 0.26367188,\n",
       " -0.13769531,\n",
       " -0.45898438,\n",
       " -0.046875,\n",
       " -0.12695312,\n",
       " -0.042236328,\n",
       " -0.16699219,\n",
       " 0.12695312,\n",
       " 0.25976562,\n",
       " -0.24414062,\n",
       " -0.21972656,\n",
       " -0.08691406,\n",
       " 0.15917969,\n",
       " -0.037841797,\n",
       " 0.008972168,\n",
       " -0.27734375,\n",
       " -0.10498047,\n",
       " -0.17578125,\n",
       " 0.22851562,\n",
       " -0.02709961,\n",
       " 0.28515625,\n",
       " -0.2734375,\n",
       " 0.016113281,\n",
       " 0.05908203,\n",
       " -0.23925781,\n",
       " 0.17773438,\n",
       " -0.13476562,\n",
       " 0.13867188,\n",
       " 0.35351562,\n",
       " 0.12207031,\n",
       " 0.14355469,\n",
       " 0.092285156,\n",
       " 0.22949219,\n",
       " -0.30078125,\n",
       " -0.048828125,\n",
       " -0.1796875,\n",
       " 0.296875,\n",
       " 0.17578125,\n",
       " 0.048095703,\n",
       " -0.0033874512,\n",
       " 0.07910156,\n",
       " -0.23828125,\n",
       " -0.23144531,\n",
       " 0.16601562,\n",
       " -0.21386719,\n",
       " -0.0703125,\n",
       " -0.075683594,\n",
       " 0.19628906,\n",
       " -0.12988281,\n",
       " -0.10595703,\n",
       " -0.35351562,\n",
       " -0.11669922,\n",
       " -0.05102539,\n",
       " 0.033935547,\n",
       " -0.14355469,\n",
       " -0.00390625,\n",
       " 0.17382812,\n",
       " -0.099609375,\n",
       " -0.16601562,\n",
       " -0.08544922,\n",
       " -0.3828125,\n",
       " 0.05908203,\n",
       " -0.06225586,\n",
       " 0.088378906,\n",
       " -0.08886719,\n",
       " 0.328125,\n",
       " 0.068359375,\n",
       " -0.19140625,\n",
       " -0.0008354187,\n",
       " 0.104003906,\n",
       " 0.15234375,\n",
       " -0.0015335083,\n",
       " 0.41601562,\n",
       " -0.033203125,\n",
       " 0.14941406,\n",
       " 0.2421875,\n",
       " -0.17675781,\n",
       " -0.049316406,\n",
       " -0.12451172,\n",
       " 0.12597656,\n",
       " 0.17480469,\n",
       " 0.28125,\n",
       " -0.18066406,\n",
       " 0.103027344,\n",
       " -0.27539062,\n",
       " 0.26171875,\n",
       " 0.24609375,\n",
       " -0.04711914,\n",
       " 0.0625,\n",
       " 0.41601562,\n",
       " -0.35546875,\n",
       " 0.22265625]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.loads(\n",
    "    myconn\n",
    "    .table(\"GOOGLE_NEWS\", schema=\"VECTORS\")\n",
    "    .filter(\"WORD = 'dog'\")\n",
    "    .select(('TO_NVARCHAR(WV)',\"WORD_VECTOR\"))\n",
    "    .head(1)\n",
    "    .collect()\n",
    "    .WORD_VECTOR[0]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
